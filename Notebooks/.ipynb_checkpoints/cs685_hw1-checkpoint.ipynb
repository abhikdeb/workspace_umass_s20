{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import TweetTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from string import punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import heapq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\debab\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\debab\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\debab\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\wordnet.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pck_data = \"D:/UMass/Spring20/685/Homework/data/save.pickle\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pickle.load(open(pck_data, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(250, 8)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data       RT @Gatita_kristal1: Follow 👉 🇲🇽☆ @OfficialTea...\n",
       "Length                                                   114\n",
       "ReTweet                                                 True\n",
       "Handle                                      @Gatita_kristal1\n",
       "Links                              [https://t.co/BNrJ3AVej8]\n",
       "Type                                                    None\n",
       "Label                                               Positive\n",
       "Notes                                                   None\n",
       "Name: 27, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[27]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Data</th>\n",
       "      <th>Length</th>\n",
       "      <th>ReTweet</th>\n",
       "      <th>Handle</th>\n",
       "      <th>Links</th>\n",
       "      <th>Type</th>\n",
       "      <th>Label</th>\n",
       "      <th>Notes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>@jazmine_cagubat Tight hug****</td>\n",
       "      <td>30</td>\n",
       "      <td>False</td>\n",
       "      <td>@jazmine_cagubat</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Positive</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>RT @forasiah: me first hearing about the live ...</td>\n",
       "      <td>140</td>\n",
       "      <td>True</td>\n",
       "      <td>@forasiah</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>RT @atBenSmith: Regardless of what side of the...</td>\n",
       "      <td>139</td>\n",
       "      <td>True</td>\n",
       "      <td>@atBenSmith</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Positive</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>RT @B0SSofB0SS3S: Bitches messy AF these nigga...</td>\n",
       "      <td>56</td>\n",
       "      <td>True</td>\n",
       "      <td>@B0SSofB0SS3S</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Negative</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>RT @CB__Knows: real live Florida shit man 😂🌴 h...</td>\n",
       "      <td>68</td>\n",
       "      <td>True</td>\n",
       "      <td>@CB__Knows</td>\n",
       "      <td>[https://t.co/mwKEEBAzE9]</td>\n",
       "      <td>None</td>\n",
       "      <td>Positive</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Data Length ReTweet  \\\n",
       "0                     @jazmine_cagubat Tight hug****     30   False   \n",
       "1  RT @forasiah: me first hearing about the live ...    140    True   \n",
       "2  RT @atBenSmith: Regardless of what side of the...    139    True   \n",
       "3  RT @B0SSofB0SS3S: Bitches messy AF these nigga...     56    True   \n",
       "4  RT @CB__Knows: real live Florida shit man 😂🌴 h...     68    True   \n",
       "\n",
       "             Handle                      Links  Type     Label Notes  \n",
       "0  @jazmine_cagubat                       None  None  Positive  None  \n",
       "1         @forasiah                       None  None   Neutral  None  \n",
       "2       @atBenSmith                       None  None  Positive  None  \n",
       "3     @B0SSofB0SS3S                       None  None  Negative  None  \n",
       "4        @CB__Knows  [https://t.co/mwKEEBAzE9]  None  Positive  None  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "87"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['Label'] == 'Positive'].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "84"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['Label'] == 'Negative'].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "79"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['Label'] == 'Neutral'].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'RT @Gatita_kristal1: Follow 👉 🇲🇽☆ @OfficialTeamTNT ☆🇲🇽   Follow 👉 🇲🇽☆ @OfficialTeamTNT ☆🇲🇽 https://t.co/BNrJ3AVej8'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tstr = df['Data'].iloc[27]\n",
    "tstr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RT  Follow 👉 🇲🇽☆  ☆🇲🇽   Follow 👉 🇲🇽☆  ☆🇲🇽 https://t.co/BNrJ3AVej8\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'RT  Follow 👉 🇲🇽☆  ☆🇲🇽   Follow 👉 🇲🇽☆  ☆🇲🇽 https://t.co/BNrJ3AVej8'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "while len(re.findall(r'@[^ :]*:?', tstr)) >= 1:\n",
    "    tstr = re.sub(r'@[^ :]*:?', '', tstr)\n",
    "    print(tstr)\n",
    "tstr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'RT  Follow 👉 🇲🇽☆  ☆🇲🇽   Follow 👉 🇲🇽☆  ☆🇲🇽 '"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tstr = re.sub(r\"http[s]?:\\/\\/[^ \\n]*\", '', tstr)\n",
    "tstr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'RT Follow 👉 🇲🇽☆ ☆🇲🇽 Follow 👉 🇲🇽☆ ☆🇲🇽 '"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tstr = re.sub(r\"\\s+\", ' ', tstr)\n",
    "tstr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'follow 👉 🇲🇽☆ ☆🇲🇽 follow 👉 🇲🇽☆ ☆🇲🇽'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tstr = re.sub(r\"^RT \", '', tstr)\n",
    "tstr = re.sub(r'[‘’]', '', tstr)\n",
    "tstr = tstr.lower().strip()\n",
    "tstr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['follow',\n",
       " '👉',\n",
       " '🇲',\n",
       " '🇽',\n",
       " '☆',\n",
       " '☆',\n",
       " '🇲',\n",
       " '🇽',\n",
       " 'follow',\n",
       " '👉',\n",
       " '🇲',\n",
       " '🇽',\n",
       " '☆',\n",
       " '☆',\n",
       " '🇲',\n",
       " '🇽']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tknzr = TweetTokenizer()\n",
    "test_str1 = tknzr.tokenize(tstr)\n",
    "test_str1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['follow', '👉', '🇲🇽☆', '☆🇲🇽', 'follow', '👉', '🇲🇽☆', '☆🇲🇽']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_str = nltk.word_tokenize(tstr)\n",
    "test_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['follow',\n",
       " '👉',\n",
       " '🇲',\n",
       " '🇽',\n",
       " '☆',\n",
       " '☆',\n",
       " '🇲',\n",
       " '🇽',\n",
       " 'follow',\n",
       " '👉',\n",
       " '🇲',\n",
       " '🇽',\n",
       " '☆',\n",
       " '☆',\n",
       " '🇲',\n",
       " '🇽']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table = str.maketrans('', '', punctuation)\n",
    "test_str1 = [w.translate(table) for w in test_str1]\n",
    "test_str1 = [w for w in test_str1 if len(w) > 0]\n",
    "test_str1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['follow',\n",
       " '👉',\n",
       " '🇲',\n",
       " '🇽',\n",
       " '☆',\n",
       " '☆',\n",
       " '🇲',\n",
       " '🇽',\n",
       " 'follow',\n",
       " '👉',\n",
       " '🇲',\n",
       " '🇽',\n",
       " '☆',\n",
       " '☆',\n",
       " '🇲',\n",
       " '🇽']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stops = set(stopwords.words(\"english\"))\n",
    "wrds = [w for w in test_str1 if not w in stops]\n",
    "wrds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['follow',\n",
       " '👉',\n",
       " '🇲',\n",
       " '🇽',\n",
       " '☆',\n",
       " '☆',\n",
       " '🇲',\n",
       " '🇽',\n",
       " 'follow',\n",
       " '👉',\n",
       " '🇲',\n",
       " '🇽',\n",
       " '☆',\n",
       " '☆',\n",
       " '🇲',\n",
       " '🇽']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "porter = PorterStemmer()\n",
    "wds = [porter.stem(w) for w in wrds]\n",
    "wds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['follow',\n",
       " '👉',\n",
       " '🇲',\n",
       " '🇽',\n",
       " '☆',\n",
       " '☆',\n",
       " '🇲',\n",
       " '🇽',\n",
       " 'follow',\n",
       " '👉',\n",
       " '🇲',\n",
       " '🇽',\n",
       " '☆',\n",
       " '☆',\n",
       " '🇲',\n",
       " '🇽']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "wtds = [lemmatizer.lemmatize(w) for w in wds]\n",
    "wtds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = {}\n",
    "input_X = pd.DataFrame(columns=['Tokens','Handle','Retweet','Link'])\n",
    "input_Y = pd.DataFrame(columns=['Label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = TweetTokenizer()\n",
    "stops = set(stopwords.words(\"english\"))\n",
    "porter = PorterStemmer()\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "for i in range(df.shape[0]):\n",
    "    tweet = df['Data'].iloc[i]\n",
    "    if df['ReTweet'].iloc[i] :\n",
    "        tweet = re.sub(r\"^RT \", '', tweet)\n",
    "    while len(re.findall(r'@[^ :]*:?', tweet)) >= 1:\n",
    "        tweet = re.sub(r'@[^ :]*:?', '', tweet)\n",
    "    tweet = re.sub(r\"http[s]?:\\/\\/[^ \\n]*\", '', tweet)\n",
    "    tweet = re.sub(r\"\\s+\", ' ', tweet)\n",
    "    tweet = re.sub(r'[‘’“”…]', '', tweet)\n",
    "    tweet = tweet.lower().strip()\n",
    "    tokens = tokenizer.tokenize(tweet)\n",
    "    puncs = str.maketrans('', '', punctuation)\n",
    "    tokens = [w.translate(puncs) for w in tokens]\n",
    "    tokens = [w for w in tokens if not len(w) < 1]\n",
    "    tokens = [w for w in tokens if not w in stops]\n",
    "    tokens = [porter.stem(w) for w in tokens]\n",
    "    tokens = [lemmatizer.lemmatize(w) for w in tokens]\n",
    "    for word in tokens:\n",
    "        if word not in vocab.keys():\n",
    "            vocab[word] = 1\n",
    "        else:\n",
    "            vocab[word] += 1\n",
    "    input_X.loc[i] = [tokens, df['Handle'].iloc[i], df['ReTweet'].iloc[i], df['Links'].iloc[i]]\n",
    "    input_Y.loc[i] = [df['Label'].iloc[i]]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tokens</th>\n",
       "      <th>Handle</th>\n",
       "      <th>Retweet</th>\n",
       "      <th>Link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>[tight, hug]</td>\n",
       "      <td>@jazmine_cagubat</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>[first, hear, live, action, mulan, miss, key, ...</td>\n",
       "      <td>@forasiah</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>[regardless, side, debat, your, decis, took, g...</td>\n",
       "      <td>@atBenSmith</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>[bitch, messi, af, nigga, 🤔]</td>\n",
       "      <td>@B0SSofB0SS3S</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>[real, live, florida, shit, man, 😂, 🌴]</td>\n",
       "      <td>@CB__Knows</td>\n",
       "      <td>True</td>\n",
       "      <td>[https://t.co/mwKEEBAzE9]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>245</td>\n",
       "      <td>[compil, namjoon, hand, ✋, 🏼]</td>\n",
       "      <td>@rmarchives</td>\n",
       "      <td>True</td>\n",
       "      <td>[https://t.co/QDOWKxFEB2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>246</td>\n",
       "      <td>[took, win, lefti, park, mash, basic, everi, s...</td>\n",
       "      <td>@MC25ctown</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>247</td>\n",
       "      <td>[someon, plea, take, photoshop, away]</td>\n",
       "      <td>@Ceatrix412</td>\n",
       "      <td>True</td>\n",
       "      <td>[https://t.co/zUo8NpF3ur]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>248</td>\n",
       "      <td>[fanast, collect, work, tell, remark, stori]</td>\n",
       "      <td>@GoddessIshtarX</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>249</td>\n",
       "      <td>[dont, worri, im, got, top]</td>\n",
       "      <td>@KMOoutsold</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>250 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Tokens            Handle  \\\n",
       "0                                         [tight, hug]  @jazmine_cagubat   \n",
       "1    [first, hear, live, action, mulan, miss, key, ...         @forasiah   \n",
       "2    [regardless, side, debat, your, decis, took, g...       @atBenSmith   \n",
       "3                         [bitch, messi, af, nigga, 🤔]     @B0SSofB0SS3S   \n",
       "4               [real, live, florida, shit, man, 😂, 🌴]        @CB__Knows   \n",
       "..                                                 ...               ...   \n",
       "245                      [compil, namjoon, hand, ✋, 🏼]       @rmarchives   \n",
       "246  [took, win, lefti, park, mash, basic, everi, s...        @MC25ctown   \n",
       "247              [someon, plea, take, photoshop, away]       @Ceatrix412   \n",
       "248       [fanast, collect, work, tell, remark, stori]   @GoddessIshtarX   \n",
       "249                        [dont, worri, im, got, top]       @KMOoutsold   \n",
       "\n",
       "    Retweet                       Link  \n",
       "0     False                       None  \n",
       "1      True                       None  \n",
       "2      True                       None  \n",
       "3      True                       None  \n",
       "4      True  [https://t.co/mwKEEBAzE9]  \n",
       "..      ...                        ...  \n",
       "245    True  [https://t.co/QDOWKxFEB2]  \n",
       "246   False                       None  \n",
       "247    True  [https://t.co/zUo8NpF3ur]  \n",
       "248    True                       None  \n",
       "249   False                       None  \n",
       "\n",
       "[250 rows x 4 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>245</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>246</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>247</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>248</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>249</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>250 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Label\n",
       "0    Positive\n",
       "1     Neutral\n",
       "2    Positive\n",
       "3    Negative\n",
       "4    Positive\n",
       "..        ...\n",
       "245   Neutral\n",
       "246   Neutral\n",
       "247  Negative\n",
       "248  Positive\n",
       "249  Positive\n",
       "\n",
       "[250 rows x 1 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_words = heapq.nlargest(500,vocab, key=vocab.get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1211"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "# from sklearn.feature_extraction import DictVectorizer\n",
    "# from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [] \n",
    "for data in input_X['Tokens']: \n",
    "    vector = [] \n",
    "    for word in freq_words: \n",
    "        if word in data: \n",
    "            vector.append(1) \n",
    "        else: \n",
    "            vector.append(0) \n",
    "    X.append(vector) \n",
    "X = np.asarray(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = []\n",
    "for label in input_Y['Label']:\n",
    "    if label == 'Positive':\n",
    "        Y.append(0)\n",
    "    elif label == 'Negative':\n",
    "        Y.append(1)\n",
    "    elif label == 'Neutral':\n",
    "        Y.append(2)\n",
    "Y = np.asarray(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">Train: 0=69, 1=67, 2=63 Test: 0=18, 1=17, 2=16\n",
      ">Train: 0=69, 1=67, 2=63 Test: 0=18, 1=17, 2=16\n",
      ">Train: 0=70, 1=67, 2=63 Test: 0=17, 1=17, 2=16\n",
      ">Train: 0=70, 1=67, 2=63 Test: 0=17, 1=17, 2=16\n",
      ">Train: 0=70, 1=68, 2=64 Test: 0=17, 1=16, 2=15\n"
     ]
    }
   ],
   "source": [
    "# Cross validation split\n",
    "stratkfold = StratifiedKFold(n_splits=5, random_state=0, shuffle=True)\n",
    "inp_idx = []\n",
    "for train_ix, test_ix in stratkfold.split(X,Y):\n",
    "    train_X, test_X = X[train_ix], X[test_ix]\n",
    "    train_y, test_y = Y[train_ix], Y[test_ix]\n",
    "    inp_idx.append((train_ix,test_ix))\n",
    "    train_0, train_1, train_2 = len(train_y[train_y==0]), len(train_y[train_y==1]), len(train_y[train_y==2])\n",
    "    test_0, test_1, test_2 = len(test_y[test_y==0]), len(test_y[test_y==1]), len(test_y[test_y==2])\n",
    "    print('>Train: 0=%d, 1=%d, 2=%d Test: 0=%d, 1=%d, 2=%d' % (train_0, train_1, train_2, test_0, test_1, test_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_acc = 0.0\n",
    "best_acc = -1\n",
    "best_model = None\n",
    "conf_mat = None\n",
    "class_rep = None\n",
    "for (train_idx,test_idx) in inp_idx:\n",
    "    logreg = LogisticRegression(penalty='l2',tol=0.0001,C=1.0,random_state=0, solver='lbfgs', multi_class='auto')\n",
    "    logreg.fit(X[train_idx],Y[train_idx])\n",
    "    pred_y = logreg.predict(X[test_idx])\n",
    "    acc = logreg.score(X[test_idx],Y[test_idx])\n",
    "    avg_acc += acc\n",
    "    if acc > best_acc:\n",
    "        best_acc = acc\n",
    "        best_model = logreg\n",
    "        conf_mat = metrics.confusion_matrix(Y[test_idx],pred_y)\n",
    "        class_rep = metrics.classification_report(Y[test_idx], pred_y, digits=3)\n",
    "avg_acc /= 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Model Accuracy :  0.5204313725490196\n",
      "Best Model Accuracy :  0.6274509803921569\n",
      "[[11  4  3]\n",
      " [ 3 10  4]\n",
      " [ 2  3 11]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.688     0.611     0.647        18\n",
      "           1      0.588     0.588     0.588        17\n",
      "           2      0.611     0.688     0.647        16\n",
      "\n",
      "    accuracy                          0.627        51\n",
      "   macro avg      0.629     0.629     0.627        51\n",
      "weighted avg      0.630     0.627     0.627        51\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Average Model Accuracy : \",avg_acc)\n",
    "print(\"Best Model Accuracy : \",best_acc)\n",
    "print(conf_mat)\n",
    "print(class_rep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = best_model.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_tokens = weights[0].argsort()[-10:][::-1]\n",
    "neg_tokens = weights[1].argsort()[-10:][::-1]\n",
    "neu_tokens = weights[2].argsort()[-10:][::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['got', '😂', 'look', 'movi', 'kid', 'alway', 'like', 'u', 'danc', 'let']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Top-10 positive words/ tokens\n",
    "[freq_words[i] for i in pos_tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fuck',\n",
       " 'home',\n",
       " 'feel',\n",
       " 'cri',\n",
       " 'way',\n",
       " 'bitch',\n",
       " '–',\n",
       " 'nigga',\n",
       " 'even',\n",
       " 'democrat']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Top-10 negative words/ tokens\n",
    "[freq_words[i] for i in neg_tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['️', 'park', 'clean', 'kd', 'someth', 'true', 'price', 'move', 'thing', 'n']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Top-10 neutral words/ tokens\n",
    "[freq_words[i] for i in neu_tokens]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word Embedding LogReg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1193514it [01:21, 14682.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1193514 word vectors.\n"
     ]
    }
   ],
   "source": [
    "embeddings_index = {}\n",
    "f = open('D:/workspace/glove.twitter.27B/glove.twitter.27B.200d.txt', encoding=\"utf8\")\n",
    "for line in tqdm(f):\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    try:\n",
    "        coefs = np.asarray(values[1:], dtype='float64')\n",
    "        embeddings_index[word] = coefs\n",
    "    except ValueError:\n",
    "        pass\n",
    "f.close()\n",
    "print('Found %s word vectors.' % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1193514"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(embeddings_index.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vec_emb(toks, embed_matrix):\n",
    "    M = []\n",
    "    for w in toks:\n",
    "        try:\n",
    "            M.append(embed_matrix[w])\n",
    "        except:\n",
    "            continue\n",
    "    M = np.asarray(M)\n",
    "    v = M.sum(axis=0)\n",
    "    if type(v) != np.ndarray:\n",
    "        return np.zeros(200)\n",
    "    return v / np.sqrt((v ** 2).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200,)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec_emb(input_X['Tokens'].iloc[1],embeddings_index).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 250/250 [00:00<00:00, 27791.57it/s]\n"
     ]
    }
   ],
   "source": [
    "X_g = [vec_emb(x,embeddings_index) for x in tqdm(input_X['Tokens'])]\n",
    "# X_g = np.array(X_g)\n",
    "X_g = np.vstack(X_g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_acc_g = 0.0\n",
    "best_acc_g = -1\n",
    "best_model_g = None\n",
    "conf_mat_g = None\n",
    "class_rep_g = None\n",
    "for (train_idx,test_idx) in inp_idx:\n",
    "    logreg_g = LogisticRegression(penalty='l2',tol=0.0001,C=1.0,random_state=0, solver='lbfgs', multi_class='auto')\n",
    "    logreg_g.fit(X_g[train_idx],Y[train_idx])\n",
    "    pred_y_g = logreg_g.predict(X_g[test_idx])\n",
    "    acc_g = logreg_g.score(X_g[test_idx],Y[test_idx])\n",
    "    avg_acc_g += acc_g\n",
    "    if acc_g > best_acc_g:\n",
    "        best_acc_g = acc_g\n",
    "        best_model_g = logreg_g\n",
    "        conf_mat_g = metrics.confusion_matrix(Y[test_idx],pred_y_g)\n",
    "        class_rep_g = metrics.classification_report(Y[test_idx], pred_y_g, digits=3)\n",
    "avg_acc_g /= 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Model Accuracy :  0.5114607843137255\n",
      "Best Model Accuracy :  0.6274509803921569\n",
      "[[12  4  2]\n",
      " [ 3 14  0]\n",
      " [ 6  4  6]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.571     0.667     0.615        18\n",
      "           1      0.636     0.824     0.718        17\n",
      "           2      0.750     0.375     0.500        16\n",
      "\n",
      "    accuracy                          0.627        51\n",
      "   macro avg      0.653     0.622     0.611        51\n",
      "weighted avg      0.649     0.627     0.613        51\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Average Model Accuracy : \",avg_acc_g)\n",
    "print(\"Best Model Accuracy : \",best_acc_g)\n",
    "print(conf_mat_g)\n",
    "print(class_rep_g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_g = best_model_g.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_wt_g = weights_g[0]\n",
    "neg_wt_g = weights_g[1]\n",
    "neu_wt_g = weights_g[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200,)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_wt_g.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200,)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings_index['got'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.7396184573479672"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_wt_g.dot(embeddings_index['like'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = list(vocab.keys())\n",
    "pos_list = []\n",
    "neg_list = []\n",
    "neu_list = []\n",
    "for wrd in words:\n",
    "    try:\n",
    "        wrd_emb = embeddings_index[wrd]\n",
    "    except:\n",
    "        wrd_emb = np.ones(200) * -100.0\n",
    "    pos_scr = pos_wt_g.dot(wrd_emb)\n",
    "    neg_scr = neg_wt_g.dot(wrd_emb)\n",
    "    neu_scr = neu_wt_g.dot(wrd_emb)\n",
    "    pos_list.append(pos_scr)\n",
    "    neg_list.append(neg_scr)\n",
    "    neu_list.append(neu_scr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_ix = np.array(pos_list).argsort()[-10:][::-1]\n",
    "neg_ix = np.array(neg_list).argsort()[-10:][::-1]\n",
    "neu_ix = np.array(neu_list).argsort()[-10:][::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['😁', 'societi', 'investingnew', 'mostli', '😀', 'fulli', '💉', '💊', 'dodg', '7']"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Top-10 positive words/ tokens\n",
    "[words[w] for w in pos_ix]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bitch',\n",
       " 'fuck',\n",
       " 'hate',\n",
       " 'stupid',\n",
       " 'even',\n",
       " 'shit',\n",
       " 'understand',\n",
       " 'hurt',\n",
       " 'wrong',\n",
       " 'bad']"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Top-10 negative words/ tokens\n",
    "[words[w] for w in neg_ix]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['predat',\n",
       " 'translat',\n",
       " 'classmat',\n",
       " 'hundr',\n",
       " 'disabl',\n",
       " '1st',\n",
       " '50',\n",
       " 'guilti',\n",
       " 'recipi',\n",
       " '💕']"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Top-10 neutral words/ tokens\n",
    "[words[w] for w in neu_ix]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Positive': ['😁',\n",
       "  'societi',\n",
       "  'investingnew',\n",
       "  'mostli',\n",
       "  '😀',\n",
       "  'fulli',\n",
       "  '💉',\n",
       "  '💊',\n",
       "  'dodg',\n",
       "  '7'],\n",
       " 'Negative': ['bitch',\n",
       "  'fuck',\n",
       "  'hate',\n",
       "  'stupid',\n",
       "  'even',\n",
       "  'shit',\n",
       "  'understand',\n",
       "  'hurt',\n",
       "  'wrong',\n",
       "  'bad'],\n",
       " 'Neutral': ['predat',\n",
       "  'translat',\n",
       "  'classmat',\n",
       "  'hundr',\n",
       "  'disabl',\n",
       "  '1st',\n",
       "  '50',\n",
       "  'guilti',\n",
       "  'recipi',\n",
       "  '💕']}"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_10 = {'Positive':[words[w] for w in pos_ix],'Negative':[words[w] for w in neg_ix],'Neutral':[words[w] for w in neu_ix]}\n",
    "top_10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_acc_o = 0.0\n",
    "best_acc_o = -1\n",
    "best_model_o = None\n",
    "conf_mat_o = None\n",
    "class_rep_o = None\n",
    "# if X_g.min() < 0 :\n",
    "#     X_g_new = X_g + abs(X_g.min())\n",
    "for (train_idx,test_idx) in inp_idx:\n",
    "    nb_o = MultinomialNB(alpha=1.0)\n",
    "    nb_o.fit(X[train_idx],Y[train_idx])\n",
    "    pred_y_o = nb_o.predict(X[test_idx])\n",
    "    acc_o = nb_o.score(X[test_idx],Y[test_idx])\n",
    "    avg_acc_o += acc_o\n",
    "    if acc_o > best_acc_o:\n",
    "        best_acc_o = acc_o\n",
    "        best_model_o = nb_o\n",
    "        conf_mat_o = metrics.confusion_matrix(Y[test_idx],pred_y_o)\n",
    "        class_rep_o = metrics.classification_report(Y[test_idx], pred_y_o, digits=3)\n",
    "avg_acc_o /= 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Model Accuracy :  0.4408823529411764\n",
      "Best Model Accuracy :  0.5416666666666666\n",
      "[[ 9  4  4]\n",
      " [ 2 14  0]\n",
      " [ 7  5  3]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.500     0.529     0.514        17\n",
      "           1      0.609     0.875     0.718        16\n",
      "           2      0.429     0.200     0.273        15\n",
      "\n",
      "    accuracy                          0.542        48\n",
      "   macro avg      0.512     0.535     0.502        48\n",
      "weighted avg      0.514     0.542     0.507        48\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Average Model Accuracy : \",avg_acc_o)\n",
    "print(\"Best Model Accuracy : \",best_acc_o)\n",
    "print(conf_mat_o)\n",
    "print(class_rep_o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_acc_o = 0.0\n",
    "best_acc_o = -1\n",
    "best_model_o = None\n",
    "conf_mat_o = None\n",
    "class_rep_o = None\n",
    "if X_g.min() < 0 :\n",
    "    X_g_new = X_g + abs(X_g.min())\n",
    "for (train_idx,test_idx) in inp_idx:\n",
    "    nb_o = MultinomialNB(alpha=1.0)\n",
    "    nb_o.fit(X_g_new[train_idx],Y[train_idx])\n",
    "    pred_y_o = nb_o.predict(X_g_new[test_idx])\n",
    "    acc_o = nb_o.score(X_g_new[test_idx],Y[test_idx])\n",
    "    avg_acc_o += acc_o\n",
    "    if acc_o > best_acc_o:\n",
    "        best_acc_o = acc_o\n",
    "        best_model_o = nb_o\n",
    "        conf_mat_o = metrics.confusion_matrix(Y[test_idx],pred_y_o)\n",
    "        class_rep_o = metrics.classification_report(Y[test_idx], pred_y_o, digits=3)\n",
    "avg_acc_o /= 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Model Accuracy :  0.4232450980392157\n",
      "Best Model Accuracy :  0.5098039215686274\n",
      "[[16  1  1]\n",
      " [10  7  0]\n",
      " [12  1  3]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.421     0.889     0.571        18\n",
      "           1      0.778     0.412     0.538        17\n",
      "           2      0.750     0.188     0.300        16\n",
      "\n",
      "    accuracy                          0.510        51\n",
      "   macro avg      0.650     0.496     0.470        51\n",
      "weighted avg      0.643     0.510     0.475        51\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Average Model Accuracy : \",avg_acc_o)\n",
    "print(\"Best Model Accuracy : \",best_acc_o)\n",
    "print(conf_mat_o)\n",
    "print(class_rep_o)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_acc_s = 0.0\n",
    "best_acc_s = -1\n",
    "best_model_s = None\n",
    "conf_mat_s = None\n",
    "class_rep_s = None\n",
    "for (train_idx,test_idx) in inp_idx:\n",
    "    svc = SVC(gamma='scale', probability=True, random_state=0)\n",
    "    svc.fit(X[train_idx],Y[train_idx])\n",
    "    pred_y_s = svc.predict(X[test_idx])\n",
    "    acc_s = svc.score(X[test_idx],Y[test_idx])\n",
    "    avg_acc_s += acc_s\n",
    "    if acc_s > best_acc_s:\n",
    "        best_acc_s = acc_s\n",
    "        best_model_s = svc\n",
    "        conf_mat_s = metrics.confusion_matrix(Y[test_idx],pred_y_s)\n",
    "        class_rep_s = metrics.classification_report(Y[test_idx], pred_y_s, digits=3)\n",
    "avg_acc_s /= 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Model Accuracy :  0.468578431372549\n",
      "Best Model Accuracy :  0.6078431372549019\n",
      "[[13  0  5]\n",
      " [ 7  7  3]\n",
      " [ 3  2 11]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.565     0.722     0.634        18\n",
      "           1      0.778     0.412     0.538        17\n",
      "           2      0.579     0.688     0.629        16\n",
      "\n",
      "    accuracy                          0.608        51\n",
      "   macro avg      0.641     0.607     0.600        51\n",
      "weighted avg      0.640     0.608     0.601        51\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Average Model Accuracy : \",avg_acc_s)\n",
    "print(\"Best Model Accuracy : \",best_acc_s)\n",
    "print(conf_mat_s)\n",
    "print(class_rep_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_acc_s = 0.0\n",
    "best_acc_s = -1\n",
    "best_model_s = None\n",
    "conf_mat_s = None\n",
    "class_rep_s = None\n",
    "for (train_idx,test_idx) in inp_idx:\n",
    "    svc = SVC(gamma='scale', probability=True, random_state=0)\n",
    "    svc.fit(X_g[train_idx],Y[train_idx])\n",
    "    pred_y_s = svc.predict(X_g[test_idx])\n",
    "    acc_s = svc.score(X_g[test_idx],Y[test_idx])\n",
    "    avg_acc_s += acc_s\n",
    "    if acc_s > best_acc_s:\n",
    "        best_acc_s = acc_s\n",
    "        best_model_s = svc\n",
    "        conf_mat_s = metrics.confusion_matrix(Y[test_idx],pred_y_s)\n",
    "        class_rep_s = metrics.classification_report(Y[test_idx], pred_y_s, digits=3)\n",
    "avg_acc_s /= 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Model Accuracy :  0.49168627450980384\n",
      "Best Model Accuracy :  0.5686274509803921\n",
      "[[10  5  3]\n",
      " [ 3 12  2]\n",
      " [ 5  4  7]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.556     0.556     0.556        18\n",
      "           1      0.571     0.706     0.632        17\n",
      "           2      0.583     0.438     0.500        16\n",
      "\n",
      "    accuracy                          0.569        51\n",
      "   macro avg      0.570     0.566     0.562        51\n",
      "weighted avg      0.570     0.569     0.563        51\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Average Model Accuracy : \",avg_acc_s)\n",
    "print(\"Best Model Accuracy : \",best_acc_s)\n",
    "print(conf_mat_s)\n",
    "print(class_rep_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
